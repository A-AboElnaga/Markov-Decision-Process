# Markov Decision Process

##  Table of Contents
- I. Introduction:........................................................................................ 2
- II. General concepts:............................................................................... 2
- III. Sequential Decisions ........................................................................ 3
  - a. Markov Decision Process:................................................................ 3
    - 1. Markov Property: .......................................................................... 3
    - 2. Markov Chain (process) and Markov Decision Process (MDP): .... 4
- IV. Decision Processes ........................................................................... 4
- V. Policies .............................................................................................. 5
- VI. Value of a Policy.............................................................................. 5
- VII. Value of an Optimal Policy............................................................. 6
- VIII. Solutions Algorithms to Markov Decision Process: ...................... 7
  - a. Policy iteration: ............................................................................... 7
  - b. Value iteration:................................................................................ 7
  - c. Value Iteration in practice: .............................................................. 8
  - d. Q-Learning: ...................................................................................... 9
  - e. Sample problem to solve and explain algorithm: ............................ 9
  - f. Exploitation vs Exploration (Îµ -greedy): ........................................ 10
- IX. Basic Elements of an MDP model:................................................. 10
  - a. State-space: ................................................................................... 10
  - b. Action-space: ................................................................................. 10
  - c. Transition probability matrices: .................................................... 11
  - d. Optimal policy: .............................................................................. 12
  - e. Conclusion: .................................................................................... 12
- X. References:...................................................................................... 13
